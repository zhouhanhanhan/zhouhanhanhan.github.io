[{"authors":["admin"],"categories":null,"content":"Hi! I\u0026rsquo;m an incoming PhD student in compuer science at the University of Waterloo. I am fortunately advised by Yang Lu. I have previously working as a data analyst at Baidu from 2020 to 2023. I graduated form the University of Hong Kong with a Master's degree in Computer Science in 2020. Before that, I received my I received my B.S. in Management from Southwestern University of Finance and Economics in 2018. \nMy primary research focus is to enable scientific discoveries using trustworthy machine learning methods, specifically in the comprehension of biological data. \n","date":1682899200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1682943621,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://qtli.github.io/author/qintong-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/qintong-li/","section":"authors","summary":"Hi! I\u0026rsquo;m an incoming PhD student in compuer science at the University of Waterloo. I am fortunately advised by Yang Lu.","tags":null,"title":"Han Zhou","type":"authors"},{"authors":[],"categories":[],"content":"","date":1684823611,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684823611,"objectID":"00b9d38496eb9c2aa97ffd2f12c8af4b","permalink":"https://qtli.github.io/publication/protein/","publishdate":"2023-05-23T14:33:31+08:00","relpermalink":"/publication/protein/","section":"publication","summary":"","tags":[],"title":"","type":"publication"},{"authors":["Yafu Li","Qintong Li","Leyang Cui","Wei Bi","Longyue Wang","Linyi Yang","Shuming Shi","Yue Zhang"],"categories":[],"content":"","date":1684823153,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684823153,"objectID":"ceb44d1e27e66bdaaa5ff4e843a7b34b","permalink":"https://qtli.github.io/publication/detection/","publishdate":"2023-05-23T14:25:53+08:00","relpermalink":"/publication/detection/","section":"publication","summary":"Recent advances in large language models highlights the importance of deepfake text detection to avoid potential risks such as fake news propagation and plagiarism. We build a wild testbed by gathering texts from various human writings and deepfake texts generated by different LLMs.","tags":[],"title":"Deepfake Text Detection in the Wild","type":"publication"},{"authors":["Qintong Li","Zhiyong Wu","Lingpeng Kong","Wei Bi"],"categories":[],"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682943621,"objectID":"218ed2f11984f83460da19e30f974061","permalink":"https://qtli.github.io/publication/eib/","publishdate":"2023-05-01T12:20:21.456496Z","relpermalink":"/publication/eib/","section":"publication","summary":"Explanations generated through single-pass prompting often lack sufficiency and conciseness, we develop an information bottleneck method to produce refined explanations that are sufficient and concise. (Findings of ACL 2023)","tags":["explanation generation","information bottleneck"],"title":"Explanation Regeneration via Information Bottleneck","type":"publication"},{"authors":["Jiyue Jiang","Sheng Wang","Qintong Li","Lingpeng Kong","Chuan Wu"],"categories":[],"content":"","date":1682726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682770821,"objectID":"c7f2e7a9a291730bddd9c641733dc982","permalink":"https://qtli.github.io/publication/csconv/","publishdate":"2023-04-29T12:20:21.456496Z","relpermalink":"/publication/csconv/","section":"publication","summary":"When communicating with elders with cognitive impairment, cognitive stimulation (CS) helps to maintain the cognitive health of elders. We construct a Chinese CS conversation dataset and propose a multi-source knowledge fusion method for CS dialogue. (ACL 2023)","tags":["dialogue generation","cognitive stimulation"],"title":"A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment","type":"publication"},{"authors":["Jiacheng Ye","Jiahui Gao","Qintong Li","Hang Xu","Jiangtao Feng","Zhiyong Wu","Tao Yu","Lingpeng Kong"],"categories":[],"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638361221,"objectID":"1a2e4cd285441b7eed1668bdf12fd70b","permalink":"https://qtli.github.io/publication/zerogen/","publishdate":"2022-12-01T12:20:21.456496Z","relpermalink":"/publication/zerogen/","section":"publication","summary":"We study a flexible and efficient zero-short learning method. Given a zero-shot task, we first generate a dataset from scratch using PLMs in an unsupervised manner. Then, we train a tiny task model under the supervision of the synthesized dataset. (EMNLP 2022)","tags":["dataset generation","zero-shot learning"],"title":"Efficient Zero-shot Learning via Dataset Generation","type":"publication"},{"authors":["Qintong Li","Piji Li","Wei Bi","Zhaochun Ren","Yuxuan Lai","Lingpeng Kong"],"categories":[],"content":"","date":1653223235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653223235,"objectID":"65fcb9db40892fa0b7ea631b918ac13b","permalink":"https://qtli.github.io/publication/eventplan4textgen/","publishdate":"2022-03-16T20:40:35+08:00","relpermalink":"/publication/eventplan4textgen/","section":"publication","summary":"A novel two-stage method which explicitly arranges the ensuing events in open-ended text generation. (Findings of ACL 2022)","tags":["open-ended text generation","event"],"title":"Event Transition Planning for Open-ended Text Generation","type":"publication"},{"authors":["Qintong Li","Piji Li","Zhaochun Ren","Pengjie Ren","Zhumin Chen"],"categories":[],"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638361221,"objectID":"f301b48b02e943dbd36dd8702d99c1b0","permalink":"https://qtli.github.io/publication/kemp/","publishdate":"2021-12-01T12:20:21.456496Z","relpermalink":"/publication/kemp/","section":"publication","summary":"The first attempt to leverage external knowledge to accurately perceive and appropriately express implicit emotions in empathetic dialogue generation. (AAAI 2022)","tags":["empathetic dialogue generation","knowledge"],"title":"Knowledge Bridging for Empathetic Dialogue Generation","type":"publication"},{"authors":null,"categories":null,"content":"I serve as a teacher assistant for course Natural Language Processing COMP3361. (2021 Fall, 2022 Fall)\n","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"996fa153b68c9c13f79ee77c978ab094","permalink":"https://qtli.github.io/post/ta/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/post/ta/","section":"post","summary":"I serve as a teacher assistant for course Natural Language Processing COMP3361. (2021 Fall, 2022 Fall)","tags":null,"title":"TA of COMP3361","type":"post"},{"authors":null,"categories":null,"content":"Description eComTag is collected from Chinese e-commerce websites, containing reviews and opinion tags for 50,068 items. This dataset is to facilitate the abstractive opinion tagging task, which aims to generate opinion tags based on large volumes of item reviews.\nDisclaimer The eComTag dataset is available strictly for non-commercial research purposes only.\n  All reviews and tags are obtained from the Internet, which is not the property of the authors, or any associated employers, entities or institutions. We do not bear responsibility for either the content or meaning of these reviews and answers.\n  By requesting and/or using this dataset, you agree not to reproduce, duplicate, copy, sell, trade, resell, rent or exploit for any commercial purpose, any portion of the contexts and any portion of derived data.\n  We reserve the right to terminate your access to the eComTag dataset at any time.\n  Download Please use this Google form to submit your information and request access to eComTag.\nData Format Readers can directly refer to the README.md in the downloaded file for more extensive instructions. Also, we provide a brief overview in the github repository.\nThe whole dataset, including train, validation, and test, is saved in a pickle file (ecomtag_dataset_preproc.p) Besides, we provide items by domain for future work.\nPaper  Abstractive Opinion Tagging\nQintong Li, Piji Li, Xinyi Li, Zhaochun Ren, Zhumin Chen, and Maarten de Rijke.\n@inproceedings{li2020aot, title={Abstractive Opinion Tagging}, author={Qintong, Li and Piji, Li and Xinyi Li and Zhaochun, Ren and Zhumin, Chen and Maarten, de Rijke}, booktitle={WSDM}, year={2021} }  Contact Please reach out to qtleo@outlook.com for any questions about the dataset.\n","date":1613088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613088000,"objectID":"8da99d8c7a684e342ae775bf9a75ea37","permalink":"https://qtli.github.io/project/ecomtag/","publishdate":"2021-02-12T00:00:00Z","relpermalink":"/project/ecomtag/","section":"project","summary":"Our collected eComtag dataset for abstractive opinion tagging research.","tags":["Deep Learning"],"title":"eComTag Dataset","type":"project"},{"authors":["Qintong Li","Piji Li","Xinyi Li","Zhaochun Ren","Zhumin Chen","Maarten de Rijke"],"categories":[],"content":"","date":1602859393,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602859393,"objectID":"de41299e57a113220c897a69a8336ea1","permalink":"https://qtli.github.io/publication/aot/","publishdate":"2020-10-16T22:43:13+08:00","relpermalink":"/publication/aot/","section":"publication","summary":"We propose a new task, abstractive opinion tagging, and a dataset, eComTag, to generate opinion tags based on large volumes of item reviews. (WSDM 2021, oral paper)","tags":["opinion summarization"],"title":"Abstractive Opinion Tagging","type":"publication"},{"authors":[],"categories":[],"content":"A humanized dialogue system is expected to generate empathetic replies, which should be sensitive to the users’ expressed emotion. The task of empathetic dialogue generation is proposed to address this problem. The essential challenges lie in (1) accurately capturing the nuances of human emotion, (2) modelling complex emotional dependencies between conversation partners, and (3) considering the potential of user feedback, which are overlooked by the majority of existing work. In response to this problem, we propose two empathetic dialogue generation frameworks in two different directions.\n  Figure 1: An empathetic dialogue example from dataset EmpatheticDialogues. The emotional-related words are highlighted in blue. \u0026ldquo;Proud\u0026rdquo; is the coarse-grained emotional label. These emotional words are labelled by an external emotion lexicon (Mohammad and Turney, 2013).   As shown in Figure 1, we list an example from the benchmark dataset EmpatheticDialogues (Rashkin et al., 2019). Notably, emotional words in the three serial utterances between interlocutors have nuanced emotional connections, i.e., “new, job” in utterance 1, “amazing, excited” in utterance 2, and “excited” in utterance 3. Without considering fine-grained emotional words, the responses generated by existing methods are trivialand uninformed, even though they expressed the appropriate emotions. Therefore, explicitly modellingthe fine-grained emotional factor is necessary.\nWe propose a multi-resolution adversarial model – EmpDG, to generate more empathetic responses, which is accepted by COLING 2020.\nEmpDG exploits both the coarse-grained dialogue-level and fine-grained token-level emotions, the latter of which helps to better capture the nuances of user emotion. In addition, we introduce an interactive adversarial learning framework which exploits the user feedback, to identify whether the generated responses evoke emotion perceptivity in dialogues. Experimental results show that the proposed approach significantly outperforms the state-of-the-art baselines in both content quality and emotion perceptivity.\n  Figure 2: An example of empathetic dialogues with external knowledge from EmpatheticDialogues. Emotional-related words in the dialogue are highlighted in red color, whereas emotion-related concepts are marked in blue. Numbers in parentheses denote emotional intensity values.   Lacking external knowledge makes it difficult to perceive implicit emotionsfrom limited dialogue history. To address the above challenges,we propose to leverage multi-type knowledge, i.e, the commonsense knowledge and emotional lexicon, to explicitly understand and express emotions in empathetic dialogue generation.\nWe propose a multi-type knowledge aware empathetic dialogue generation framework, to explicitly understand and express emotions in empathetic dialogue generation, which is submitted to AAAI 2021.\nWe first enrich the dialogue history by jointly interactingwith two-type knowledge and construct an emotional contextgraph. Then we introduce a multi-type knowledge-aware context encoder to learn emotional context representations anddistill emotional signals, which are the prerequisites to predicate emotions expressed in responses. Finally, we proposean emotional cross-attention mechanism to exploit the emotional dependencies between the emotional context graph andthe target empathetic response. The proposed framework makes it easier to accurately perceive and appropriately express implicit emotions.\n","date":1602141522,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602141522,"objectID":"8b5bf5a8e2975ce4d7c20dd3c23761a0","permalink":"https://qtli.github.io/project/emp_dia_gen/","publishdate":"2020-10-08T15:18:42+08:00","relpermalink":"/project/emp_dia_gen/","section":"project","summary":"A humanized dialogue system is expected to generate empathetic replies, which should be sensitive to the users’ expressed emotion. The task of empathetic dialogue generation is proposed to address this problem.","tags":[],"title":"Empathetic Dialogue Generation","type":"project"},{"authors":["Qintong Li","Hongshen Chen","Zhaochun Ren","Pengjie Ren","Zhaopeng Tu","Zhumin Chen"],"categories":[],"content":"","date":1601642435,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601642435,"objectID":"5c53a2582314c00b07153a862f3d835b","permalink":"https://qtli.github.io/publication/empdg/","publishdate":"2020-10-02T20:40:35+08:00","relpermalink":"/publication/empdg/","section":"publication","summary":"A multi-resolution adversarial model -- EmpDG, to generate more empathetic responses. (COLING 2020, oral paper)","tags":["empathetic dialogue generation","adversarial learning"],"title":"EmpDG: Multi-resolution Interactive Empathetic Dialogue Generation","type":"publication"},{"authors":[],"categories":[],"content":"Given single-documents or multi-documents, summarizing the opinions expressed of the input is a vital task in NLP. I divide the current researches into two categories: keyphrase generation and opinion summarization.\nKeyphrase generation: A lot of research has been conducted on generating keyphrases tosummarize various types of text. Early approaches to keyphrase generation extract important phrasesfrom the document as the results. Sequence tagging models havebeen applied to identify keyphrases. Retrieval-based approaches utilize a two-step pipeline to extract and rank candidate keyphrases. Sun et al.[1] adopt an extractive graph-based approach, which applies a point network to generate a set of diverse keyphrases. More recently, abstractive approaches havebeen explored. Chan et al.[2] propose a reinforcement learning approach for neural keyphrase generation that encourages a model to generate both sufficient and accurate keyphrases. Wang et al.[3] propose a topic-aware neural keyphrase generation method toidentify topic words. The methods listed above only consider keyphrase generation given a single document. Our work Abstractive Opinion Tagging considers opinion tagging from multiple documents, that is, from all of the reviewsfor a given item.\nOpinion summarization: Opinion summarization has become an emerging research topicin recent years. Early studies on opinion summarization focus onextracting salient sentences from text: Hu and Liu[4] identify item features mentioned in the reviews and thenextract opinion sentences for the identified features. Unsupervised learning methods are utilized to extract a review summary by exploiting review helpfulness ratings[5]. To reduce redundancy, a greedy algorithm is also applied to form the final summaries[6]. Reflecting the most representative opinions from reviewers, manyrecent studies have shown that abstractive approaches are more appropriate for summarizing review text: Geraniet al.[7] utilize a template filling strategy to generate a review summary; Wang and Ling[8] apply an encoder-decoder attentionmodel to generate an abstractive summary for opinionated documents. The objective of the above summarization approaches is togenerate coherent sentences to summarize opinions.\nIn contrast, we propose the abstractive opinion tagging task so as to generate opinion tags from a large number of user-generated reviews. In our scenario, opinion tags are more concise but without loss of essential information; they should help users comprehend reviews quickly and conveniently (this work has been accepted by WSDM 2021).\nReferences\n[1] Zhiqing Sun, Jian Tang, Pan Du, Zhi-Hong Deng, and Jian-Yun Nie. 2019. Div-GraphPointer: A Graph Pointer Network for Extracting Diverse Keyphrases. In SIGIR.\n[2] Hou Pong Chan, Wang Chen, Lu Wang, and Irwin King. 2019. Neural KeyphraseGeneration via Reinforcement Learning with Adaptive Rewards. In ACL.\n[3] Yue Wang, Jing Li, Hou Pong Chan, Irwin King, Michael R. Lyu, and Shuming Shi. 2019. Topic-Aware Neural Keyphrase Generation for Social Media Language. In ACL.\n[4] Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In SIGKDD.\n[5] Wenting Xiong and Diane J. Litman. 2014. Empirical Analysis of Exploiting Review Helpfulness for Extractive Summarization of Online Reviews. In COLING.\n[6] Stefanos Angelidis and Mirella Lapata. 2018. Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised. In EMNLP.\n[7] Shima Gerani, Yashar Mehdad, Giuseppe Carenini, Raymond T. Ng, and BitaNejat. 2014. Abstractive Summarization of Product Reviews Using Discourse Structure. In EMNLP.\n[8] Lu Wang and Wang Ling. 2016. Neural Network-Based Abstract Generation for Opinions and Arguments. In NAACL.\n","date":1597565539,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597565539,"objectID":"d26099eeb30179a130a5ccacc121470d","permalink":"https://qtli.github.io/project/summarization/","publishdate":"2020-08-16T16:12:19+08:00","relpermalink":"/project/summarization/","section":"project","summary":"Given single-documents or multi-documents, summarizing the opinions expressed of the input is a vital task in NLP. I divide the current researches into two categories: keyphrase generation and opinion summarization.","tags":[],"title":"Text Summarization","type":"project"}]